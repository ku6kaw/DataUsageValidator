# LLMによるデータ利用判定 (Rule 3 - アブストラクト)

## 目的
このノートブックの目的は、抽出されたアブストラクトテキストを大規模言語モデル（LLM）に入力し、論文がデータ論文を「利用しているか」を判定することです。これは、ルールベースの判定に加えて、より高度な意味理解に基づく判定を試みるものです。

## 達成状況
- Gemini APIキーを設定し、モデルを初期化しました。
- `prompts/zero_shot_abstract.txt` からプロンプトテンプレートを読み込みました。
- `samples_with_text.csv` からアブストラクトを含む論文データを読み込み、アブストラクトが空の論文を除外しました。
- 各論文のアブストラクトとタイトルをプロンプトに埋め込み、LLMにデータ利用の有無を判定させました。
- LLMの応答から判定結果（"Used"または"Not Used"）を抽出し、数値（1または0）に変換しました。
- 予測結果を `data/processed/prediction_llm.csv` に保存しました。

## 成果物
- `prediction_llm.csv`: LLM（アブストラクトベース）によるデータ利用の予測結果。

---

import pandas as pd
import os
import sys

# srcディレクトリをパスに追加
sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))

from src.llm_validator import (
    configure_gemini_api,
    load_prompt_template,
    run_llm_prediction,
    save_llm_predictions
)
from src.config import (
    GEMINI_API_KEY,
    PROMPT_FILE_ZERO_SHOT_ABSTRACT,
    OUTPUT_FILE_SAMPLES_WITH_TEXT,
    OUTPUT_FILE_PREDICTION_LLM
)

# --- メイン処理 ---
if __name__ == "__main__":
    try:
        # 1. Gemini APIの設定
        configure_gemini_api(api_key=GEMINI_API_KEY)
        
        # 2. プロンプトテンプレートの読み込み
        prompt_template = load_prompt_template(PROMPT_FILE_ZERO_SHOT_ABSTRACT)
        
        # 3. 処理対象データの準備
        df_to_process = pd.read_csv(OUTPUT_FILE_SAMPLES_WITH_TEXT)
        # アブストラクトが空の行は除外
        df_to_process.dropna(subset=['abstract'], inplace=True) 
        
        # 4. LLMによる予測の実行
        df_predictions = run_llm_prediction(
            df_to_process=df_to_process,
            prompt_template=prompt_template,
            text_column='abstract',
            prediction_column_name='prediction_rule3_abstract'
        )
        
        # 5. 結果の保存
        save_llm_predictions(df_predictions, output_file_path=OUTPUT_FILE_PREDICTION_LLM)
        
        print("\n--- LLM(Abstract)の予測結果の内訳 ---")
        print(df_predictions['prediction_rule3_abstract'].value_counts())

    except Exception as e:
        print(f"LLMアブストラクト予測のメイン処理中にエラーが発生しました: {e}")
