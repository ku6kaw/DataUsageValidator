{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc73e017",
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR_API_KEY=\"AIzaSyCLcPYlxiieOjJ2BU7xRUL1Pn1iUocyHHA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e99d478b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APIキーの設定が完了しました。\n",
      "プロンプトファイルを正常に読み込みました。\n",
      "合計 194 件の論文に対してLLMの判定を実行します。\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3488fb0cbeb43c7844b74e9f600f8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LLM(Abstract)で判定中:   0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOI 10.1016/j.enmm.2022.100753 の処理中にエラーが発生しました: 500 Internal error encountered.\n",
      "\n",
      "処理完了。LLM(Abstract)の予測結果を '../data/processed/prediction_llm.csv' に保存しました。\n",
      "\n",
      "--- 保存された結果の内訳 ---\n",
      "prediction_rule3_abstract\n",
      " 0    181\n",
      " 1     12\n",
      "-1      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "\n",
    "# --- 1. 設定 ---\n",
    "\n",
    "# 【重要】ご自身のAPIキーに置き換えてください\n",
    "try:\n",
    "    genai.configure(api_key=\"AIzaSyCLcPYlxiieOjJ2BU7xRUL1Pn1iUocyHHA\") \n",
    "    print(\"APIキーの設定が完了しました。\")\n",
    "except Exception as e:\n",
    "    print(f\"APIキーの設定でエラー: {e}\")\n",
    "    # キー設定が失敗した場合は、ここで処理を中断\n",
    "    exit()\n",
    "\n",
    "# モデルを設定\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "# 入力ファイルと出力ファイル\n",
    "INPUT_CSV = '../data/processed/samples_with_text.csv'\n",
    "PROMPT_FILE_PATH = '../prompts/zero_shot_abstract.txt' # テストで成功したプロンプト\n",
    "OUTPUT_FILE = '../data/processed/prediction_llm.csv'\n",
    "\n",
    "# --- 2. プロンプトとデータの準備 ---\n",
    "try:\n",
    "    with open(PROMPT_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        PROMPT_TEMPLATE = f.read()\n",
    "    print(\"プロンプトファイルを正常に読み込みました。\")\n",
    "    \n",
    "    df_to_process = pd.read_csv(INPUT_CSV)\n",
    "    # 念のため、アブストラクトが空の行は除外\n",
    "    df_to_process.dropna(subset=['abstract'], inplace=True)\n",
    "    \n",
    "    print(f\"合計 {len(df_to_process)} 件の論文に対してLLMの判定を実行します。\")\n",
    "except Exception as e:\n",
    "    print(f\"エラー: データの読み込みに失敗しました。 {e}\")\n",
    "    df_to_process = pd.DataFrame()\n",
    "\n",
    "# --- 3. LLMによる判定の本番実行 ---\n",
    "predictions = []\n",
    "if PROMPT_TEMPLATE and not df_to_process.empty:\n",
    "    for index, row in tqdm(df_to_process.iterrows(), total=len(df_to_process), desc=\"LLM(Abstract)で判定中\"):\n",
    "        \n",
    "        prompt = PROMPT_TEMPLATE.format(\n",
    "            cited_data_paper_title=row['cited_data_paper_title'],\n",
    "            citing_paper_title=row['citing_paper_title'],\n",
    "            citing_paper_abstract=row['abstract']\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            \n",
    "            # 正規表現でJSON部分を抽出\n",
    "            match = re.search(r\"\\{.*\\}\", response.text, re.DOTALL)\n",
    "            json_text = match.group(0) if match else response.text\n",
    "            json_response = json.loads(json_text)\n",
    "            \n",
    "            decision = json_response.get('decision')\n",
    "            prediction = 1 if decision == \"Used\" else 0\n",
    "            \n",
    "        except Exception as e:\n",
    "            # エラーが発生した場合、どの論文でエラーが出たかを表示\n",
    "            print(f\"DOI {row['citing_paper_doi']} の処理中にエラーが発生しました: {e}\")\n",
    "            prediction = -1 # エラー時は-1\n",
    "            \n",
    "        predictions.append(prediction)\n",
    "        time.sleep(1) # APIへの負荷を考慮し、1秒待機\n",
    "\n",
    "# --- 4. 結果の保存 ---\n",
    "if len(predictions) == len(df_to_process):\n",
    "    # 指定されたカラムで新しいDataFrameを作成\n",
    "    output_df = pd.DataFrame({\n",
    "        'citing_paper_eid': df_to_process['citing_paper_eid'],\n",
    "        'citing_paper_doi': df_to_process['citing_paper_doi'],\n",
    "        'citing_paper_title': df_to_process['citing_paper_title'],\n",
    "        'cited_data_paper_title': df_to_process['cited_data_paper_title'],\n",
    "        'prediction_rule3_abstract': predictions\n",
    "    })\n",
    "    \n",
    "    output_df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"\\n処理完了。LLM(Abstract)の予測結果を '{OUTPUT_FILE}' に保存しました。\")\n",
    "    print(\"\\n--- 保存された結果の内訳 ---\")\n",
    "    print(output_df['prediction_rule3_abstract'].value_counts())\n",
    "else:\n",
    "    print(\"処理が正常に完了しませんでした。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataUsageValidator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
