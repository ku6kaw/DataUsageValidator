# LLMによるデータ利用判定 (Rule 3 - フルテキスト)

## 目的
このノートブックの目的は、抽出された全文テキストを大規模言語モデル（LLM）に入力し、論文がデータ論文を「利用しているか」を判定することです。アブストラクトベースの判定よりも詳細な文脈を考慮した判定を試みます。

## 達成状況
- Gemini APIキーを設定し、モデルを初期化しました。
- `prompts/zero_shot_fulltext.txt` および `prompts/few_shot_cot_fulltext.txt` からプロンプトテンプレートを読み込みました。
- `samples_with_text.csv` から全文テキストを含む論文データを読み込み、全文が空の論文を除外しました。
- 各論文の全文テキストとタイトルをプロンプトに埋め込み、LLMにデータ利用の有無を判定させました。
- LLMの応答から判定結果を抽出し、数値に変換しました。
- 予測結果を `data/processed/prediction_llm.csv` に追加・更新しました。
- 失敗した予測（-1）を再試行する機能も実装しました。

## 成果物
- `prediction_llm.csv`: LLM（フルテキストベース、Zero-shotおよびFew-shot CoT）によるデータ利用の予測結果。

---

import pandas as pd
import os
import sys

# srcディレクトリをパスに追加
sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))

from src.llm_validator import (
    main_llm_fulltext_prediction,
    retry_llm_predictions
)
from src.config import (
    GEMINI_API_KEY, GEMINI_MODEL_NAME,
    PROMPT_FILE_ZERO_SHOT_FULLTEXT, PROMPT_FILE_FEW_SHOT_COT_FULLTEXT,
    OUTPUT_FILE_SAMPLES_WITH_TEXT, OUTPUT_FILE_PREDICTION_LLM
)

# --- メイン処理 ---
if __name__ == "__main__":
    # Zero-shot Full-text 予測の実行
    print("\n--- LLM (Full-text, Zero-shot) 予測を開始 ---")
    main_llm_fulltext_prediction(
        prompt_file_path=PROMPT_FILE_ZERO_SHOT_FULLTEXT,
        prediction_column_suffix='zeroshot',
        model_name=GEMINI_MODEL_NAME,
        sleep_time=1.5,
        timeout=180
    )

    # Few-shot CoT Full-text 予測の実行
    print("\n--- LLM (Full-text, Few-shot CoT) 予測を開始 ---")
    main_llm_fulltext_prediction(
        prompt_file_path=PROMPT_FILE_FEW_SHOT_COT_FULLTEXT,
        prediction_column_suffix='few_shot_cot',
        model_name=GEMINI_MODEL_NAME,
        sleep_time=1.5,
        timeout=180
    )

    # 失敗した予測の再試行の例 (必要に応じてコメントを外して実行)
    # print("\n--- 失敗したLLM予測の再試行を開始 ---")
    # retry_llm_predictions(
    #     input_samples_csv=OUTPUT_FILE_SAMPLES_WITH_TEXT,
    #     input_predictions_csv=OUTPUT_FILE_PREDICTION_LLM,
    #     column_to_retry=f"prediction_rule3_{GEMINI_MODEL_NAME.replace('.', '_')}_zeroshot", # 再試行したいカラム名
    #     prompt_file_path=PROMPT_FILE_ZERO_SHOT_FULLTEXT,
    #     text_column='full_text',
    #     model_name=GEMINI_MODEL_NAME,
    #     sleep_time=1.5,
    #     timeout=180
    # )
